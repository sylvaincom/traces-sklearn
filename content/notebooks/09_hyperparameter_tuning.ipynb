{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1a184d",
   "metadata": {},
   "source": [
    "\n",
    "# Hyperparameters tuning\n",
    "\n",
    "Previous notebooks showed how model parameters impact statistical performance. We want\n",
    "to optimize these parameters to achieve the best possible model performance. This\n",
    "optimization process is called hyperparameter tuning.\n",
    "\n",
    "This notebook demonstrates several methods to tune model hyperparameters.\n",
    "\n",
    "## Introductory example\n",
    "\n",
    "We revisit an example from the linear models notebook about the impact of the $\\alpha$\n",
    "parameter in a `Ridge` model. The $\\alpha$ parameter controls model regularization\n",
    "strength. No general rule exists for selecting a good $\\alpha$ value - it depends on\n",
    "the specific dataset.\n",
    "\n",
    "Let's load a dataset for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using JupyterLite, uncomment and install the `skrub` and `pyodide-http` packages.\n",
    "%pip install skrub\n",
    "%pip install pyodide-http\n",
    "import matplotlib.pyplot as plt\n",
    "import skrub\n",
    "\n",
    "# import pyodide_http\n",
    "# pyodide_http.patch_all()\n",
    "\n",
    "skrub.patch_display()  # makes nice display for pandas tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ead679",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f2c13",
   "metadata": {},
   "source": [
    "\n",
    "Now we define a `Ridge` model that processes data by adding feature interactions using\n",
    "a `PolynomialFeatures` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"poly\", PolynomialFeatures()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge()),\n",
    "    ]\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ca3ec",
   "metadata": {},
   "source": [
    "\n",
    "We start with scikit-learn's default parameters. Let's evaluate this basic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, X, y, cv=cv)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a075c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.aggregate([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8139cc",
   "metadata": {},
   "source": [
    "\n",
    "Nothing indicates our pipeline achieves optimal performance. The `PolynomialFeatures`\n",
    "degree might need adjustment or the `Ridge` regressor might need different\n",
    "regularization. Let's examine which parameters we could tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in model.get_params():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e9e63",
   "metadata": {},
   "source": [
    "\n",
    "Two key parameters are `scaler__degree` and `ridge__alpha`. We will find\n",
    "their optimal values for this dataset.\n",
    "\n",
    "## Manual hyperparameters search\n",
    "\n",
    "Before exploring scikit-learn's automated tuning tools, we implement a simplified\n",
    "manual version.\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "1. Create nested `for` loops to try all parameter combinations defined in\n",
    "   `parameter_grid`\n",
    "2. In the inner loop, use cross-validation on the training set to get an array of\n",
    "   scores\n",
    "3. Compute the mean and standard deviation of cross-validation scores to find the best\n",
    "   hyperparameters\n",
    "4. Train a model with the best hyperparameters and evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"poly__degree\": [1, 2, 3],\n",
    "    \"ridge__alpha\": [0.01, 0.1, 1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c7eaf",
   "metadata": {},
   "source": [
    "\n",
    "## Hyperparameters search using a grid\n",
    "\n",
    "Our manual search implements a grid-search: trying every possible parameter\n",
    "combination. Scikit-learn provides `GridSearchCV` to automate this process. During\n",
    "fitting, it performs cross-validation and selects optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f44255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_cv = GridSearchCV(model, param_grid=parameter_grid)\n",
    "search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53871cd1",
   "metadata": {},
   "source": [
    "\n",
    "The `best_params_` attribute shows the optimal parameters found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04541e",
   "metadata": {},
   "source": [
    "\n",
    "The `cv_results_` attribute provides details about all hyperparameter combinations\n",
    "tried during fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95ee6f",
   "metadata": {},
   "source": [
    "\n",
    "When `refit=True` (default), the search trains a final model using the best\n",
    "parameters. Access this model through `best_estimator_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81202228",
   "metadata": {},
   "source": [
    "\n",
    "The `best_estimator_` handles `predict` and `score` calls to `GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3023ff",
   "metadata": {},
   "source": [
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "`GridSearchCV` behaves like any classifier or regressor. Use `cross_validate` to\n",
    "evaluate the grid-search model we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3696c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692684e4",
   "metadata": {},
   "source": [
    "\n",
    "**QUESTION**:\n",
    "\n",
    "What limitations does the grid-search approach have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b62a9e",
   "metadata": {},
   "source": [
    "\n",
    "## Randomized hyperparameters search\n",
    "\n",
    "Grid-search has two main limitations:\n",
    "\n",
    "- It explores only predefined parameter combinations\n",
    "- Adding parameters or values exponentially increases search cost\n",
    "\n",
    "`RandomizedSearchCV` draws parameter values from specified distributions. This allows\n",
    "non-grid exploration of the hyperparameter space with a fixed computational budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1603d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "parameter_distributions = {\n",
    "    \"poly__degree\": np.arange(1, 5),\n",
    "    \"ridge__alpha\": loguniform(1, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search_cv = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=parameter_distributions,\n",
    "    n_iter=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9317cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(search_cv, X, y, cv=cv, return_estimator=True)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc478ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in cv_results[\"estimator\"]:\n",
    "    print(est.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd192db2",
   "metadata": {},
   "source": [
    "\n",
    "## Model with internal hyperparameter tuning\n",
    "\n",
    "Some estimators include efficient hyperparameter selection, more efficient than\n",
    "grid-search. These estimators typically end with `CV` (e.g. `RidgeCV`).\n",
    "\n",
    "**EXERCISE**:\n",
    "\n",
    "1. Create a pipeline with `PolynomialFeatures`, `StandardScaler`, and `Ridge`\n",
    "2. Create a grid-search with this pipeline and tune `alpha` using `np.logspace(-2, 2,\n",
    "   num=50)`\n",
    "3. Fit the grid-search on the training set and time it\n",
    "4. Repeat using `RidgeCV` instead of `Ridge` and remove `GridSearchCV`\n",
    "5. Compare computational performance between approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f515eb",
   "metadata": {},
   "source": [
    "\n",
    "## Inspection of hyperparameters in cross-validation\n",
    "\n",
    "When performing search cross-validation inside evaluation cross-validation, different\n",
    "hyperparameter values may emerge for each split. Let's examine this with\n",
    "`GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "inner_model = Pipeline(\n",
    "    [\n",
    "        (\"poly\", PolynomialFeatures()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge()),\n",
    "    ]\n",
    ")\n",
    "param_grid = {\"poly__degree\": [1, 2], \"ridge__alpha\": np.logspace(-2, 2, num=10)}\n",
    "model = GridSearchCV(inner_model, param_grid=param_grid, n_jobs=-1)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c8513",
   "metadata": {},
   "source": [
    "\n",
    "We run cross-validation and store models from each split by setting\n",
    "`return_estimator=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model, X, y, cv=cv, return_estimator=True)\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f39c0",
   "metadata": {},
   "source": [
    "\n",
    "The `estimator` column contains the different estimators. We examine `best_params_`\n",
    "from each `GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8732419",
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator_cv_fold in cv_results[\"estimator\"]:\n",
    "    print(estimator_cv_fold.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4ac70",
   "metadata": {},
   "source": [
    "\n",
    "This inspection reveals the stability of hyperparameter values across folds.\n",
    "\n",
    "## Note regarding the scoring metric to optimize during tuning\n",
    "\n",
    "The `GridSearchCV` and `RandomizedSearchCV` classes use the `scoring` parameter to\n",
    "define the metric to optimize during tuning. If not specified, the scoring metric used\n",
    "for classification is `accuracy` and the `r2_score` for regression.\n",
    "\n",
    "These scoring rules are actually not optimal for hyperparameter tuning. Indeed, we\n",
    "recently recognized that it is better to use proper scoring rules. Such scoring rules\n",
    "allow to get calibrated models.\n",
    "\n",
    "Therefore, we recommend to use `brier_score_loss` or `log_loss` for classification\n",
    "and `mean_squared_error` for regression."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
